# -*- coding: utf-8 -*-
"""cnn_fastai.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Fzi5tiv2EIE3WY6xfn3LAZDivDQLLSqW
"""

from fastai.vision.all import *
import torch
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

top_edge = tensor([[-1,-1,-1],
 [ 0, 0, 0],
 [ 1, 1, 1]]).float()

path = untar_data(URLs.MNIST_SAMPLE)
im3 = Image.open(path/'train'/'3'/'12.png')
show_image(im3);

im3_t = tensor(im3)
im3_t[0:3,0:3] * top_edge

(im3_t[0:3,0:3] * top_edge).sum()

df = pd.DataFrame(im3_t[:10,:20])
df.style.set_properties(**{'font-size':'6pt'}).background_gradient('Greys')

(im3_t[4:7,6:9] * top_edge).sum()

(im3_t[7:10,17:20] * top_edge).sum()

def apply_kernel(row, col, kernal):
    return (im3_t[row-1:row+2,col-1:col+2] * kernal).sum()
apply_kernel(5, 7, top_edge)

[[(i,j) for j in range(1,5)] for i in range(1,5)]

rng = range(1,27)
top_edge3 = tensor([[apply_kernel(i,j,top_edge) for j in rng] for i in rng])
show_image(top_edge3);

left_edge = tensor([[-1,1,0],
 [-1,1,0],
 [-1,1,0]]).float()
left_edge3 = tensor([[apply_kernel(i,j,left_edge) for j in rng] for i in rng])
show_image(left_edge3);

diag1_edge = tensor([[ 0,-1, 1],
 [-1, 1, 0],
 [ 1, 0, 0]]).float()
diag2_edge = tensor([[ 1,-1, 0],
 [ 0, 1,-1],
 [ 0, 0, 1]]).float()
edge_kernels = torch.stack([left_edge, top_edge, diag1_edge, diag2_edge])
edge_kernels.shape

mnist = DataBlock((ImageBlock(cls=PILImageBW), CategoryBlock),
 get_items=get_image_files,
 splitter=GrandparentSplitter(),
 get_y=parent_label)
dls = mnist.dataloaders(path)
xb,yb = first(dls.valid)
xb.shape

xb,yb = to_cpu(xb),to_cpu(yb)

edge_kernels.shape,edge_kernels.unsqueeze(1).shape

edge_kernels = edge_kernels.unsqueeze(1)
batch_features = F.conv2d(xb, edge_kernels)
batch_features.shape

show_image(batch_features[0,0]);

simple_net = nn.Sequential(
    nn.Linear(28*28,30),
    nn.ReLU(),
    nn.Linear(30,1)
)

simple_net

broken_cnn = nn.Sequential(
    nn.Conv2d(1,16,kernel_size=3,stride=2,padding=1),
    nn.ReLU(),
    nn.Conv2d(16,16,kernel_size=3,stride=2,padding=1),
)

broken_cnn(xb).shape

def conv(ni, nf, ks=3, act=True):
 res = nn.Conv2d(ni, nf, stride=2, kernel_size=ks, padding=ks//2)
 if act: res = nn.Sequential(res, nn.ReLU())
 return res

simple_cnn = sequential(
 conv(1 ,4), #14x14
 conv(4 ,8), #7x7
 conv(8 ,16), #4x4
 conv(16,32), #2x2
 conv(32,2, act=False), #1x1
 Flatten(),
)

simple_cnn(xb).shape

learn = Learner(dls, simple_cnn, loss_func=F.cross_entropy, metrics=accuracy)

learn.summary()

learn.fit_one_cycle(2, 0.01)

m = learn.model[0]
m

m[0].weight.shape

m[0].bias.shape

! wget https://bearizona.com/wp-content/uploads/2022/09/GD3A0309-1024x683.webp

im = image2tensor(Image.open('/content/GD3A0309-1024x683.webp'))
im.shape

show_image(im);

_,axs = subplots(1,3)
for bear,ax,color in zip(im,axs,('Reds','Greens','Blues')):
 show_image(255-bear, ax=ax, cmap=color)

path = untar_data(URLs.MNIST)
path.ls()

def get_dls(bs=64):
 return DataBlock(
 blocks=(ImageBlock(cls=PILImageBW), CategoryBlock),
 get_items=get_image_files,
 splitter=GrandparentSplitter('training','testing'),
 get_y=parent_label,
 batch_tfms=Normalize()
 ).dataloaders(path, bs=bs)
dls = get_dls()

dls.show_batch(max_n=9, figsize=(4,4))

def simple_cnn():
 return sequential(
 conv(1 ,8, ks=5), #14x14
 conv(8 ,16), #7x7
 conv(16,32), #4x4
 conv(32,64), #2x2
 conv(64,10, act=False), #1x1
 Flatten(),
 )

from fastai.callback.hook import *

def fit(epochs=1):
 learn = Learner(dls, simple_cnn(), loss_func=F.cross_entropy,
 metrics=accuracy, cbs=ActivationStats(with_hist=True))
 learn.fit(epochs, 0.06)
 return learn
learn = fit()

learn.activation_stats.plot_layer_stats(0)

learn.activation_stats.plot_layer_stats(-2)

dls = get_dls(512)
learn = fit()

learn.activation_stats.plot_layer_stats(-2)

def fit(epochs=1, lr=0.06):
 learn = Learner(dls, simple_cnn(), loss_func=F.cross_entropy,
 metrics=accuracy, cbs=ActivationStats(with_hist=True))
 learn.fit_one_cycle(epochs, lr)
 return learn
learn = fit()

learn.recorder.plot_sched()

learn.activation_stats.plot_layer_stats(-2)

learn.activation_stats.color_dim(-2)

def conv(ni, nf, ks=3, act=True):
 layers = [nn.Conv2d(ni, nf, stride=2, kernel_size=ks, padding=ks//2)]
 layers.append(nn.BatchNorm2d(nf))
 if act: layers.append(nn.ReLU())
 return nn.Sequential(*layers)

learn = fit()

learn.activation_stats.color_dim(-4)

learn = fit(6, lr=0.1)

